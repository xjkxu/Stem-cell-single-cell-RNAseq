---
title: "xu17_33_38"
output: html_document
---

## Load all packages
```{r}

library("rlang")
library("Seurat");
library("sctransform");
library("dplyr");
library("RColorBrewer");
library("ggthemes");
library("ggplot2");
library("cowplot");
library("data.table");
library("scales")

```


## Set up Seurat object
```{r}
## Find the origial CR path

setwd("C:/Users/Xiaosa Xu/Desktop/Seurat_2020/xu17_2017_cus_CR310_S150_L150")

setwd("C:/Users/Xiaosa Xu/Desktop/Seurat_2020/xu33_fea3cle7_L150")

setwd("C:/Users/Xiaosa Xu/Desktop/Seurat_2020/xu38_fea3cle7")


## Step 3: Read in the feature-barcode matrices generated by the cellranger pipeline.

memory.limit(size=50000000)

samples=c("xu17","xu33","xu38")

data.10x = list()

data.10x[[1]] <- Read10X(data.dir = "C:/Users/Xiaosa Xu/Desktop/Seurat_2020/xu17_2017_cus_CR310_S150_L150/raw_feature_bc_matrix");

data.10x[[2]] <- Read10X(data.dir = "C:/Users/Xiaosa Xu/Desktop/Seurat_2020/xu33_fea3cle7_L150/raw_feature_bc_matrix");

data.10x[[3]] <- Read10X(data.dir = "C:/Users/Xiaosa Xu/Desktop/Seurat_2020/xu38_fea3cle7/raw_feature_bc_matrix");


## Convert each feature-barcode matrix to a Seurat object.

scrna3.list = list(); # First create an empty list to hold the Seurat objects

scrna3.list[[1]] = CreateSeuratObject(counts = data.10x[[1]], min.cells=3, min.features=200, project=samples[1]);

scrna3.list[[1]][["DataSet"]] = samples[1];

scrna3.list[[2]] = CreateSeuratObject(counts = data.10x[[2]], min.cells=3, min.features=200, project=samples[2]);

scrna3.list[[2]][["DataSet"]] = samples[2];

scrna3.list[[3]] = CreateSeuratObject(counts = data.10x[[3]], min.cells=3, min.features=200, project=samples[3]);

scrna3.list[[3]][["DataSet"]] = samples[3];


## Optional, remove the raw data to save space:

rm(data.10x);


### Subset each library before merge or integrate


scrna3.list[[1]] <- subset(scrna3.list[[1]], subset = nCount_RNA > 5000 & nFeature_RNA > 1000 & nCount_RNA < 150000 & nFeature_RNA < 15000)

scrna3.list[[2]] <- subset(scrna3.list[[2]], subset = nCount_RNA > 5000 & nFeature_RNA > 1000 & nCount_RNA < 150000 & nFeature_RNA < 15000)

scrna3.list[[3]] <- subset(scrna3.list[[3]], subset = nCount_RNA > 5000 & nFeature_RNA > 1000 & nCount_RNA < 150000 & nFeature_RNA < 15000)



## logNormalize

scrna3.list[[1]]<- NormalizeData(scrna3.list[[1]], normalization.method = "LogNormalize", scale.factor = 10000)

scrna3.list[[2]]<- NormalizeData(scrna3.list[[2]], normalization.method = "LogNormalize", scale.factor = 10000)

scrna3.list[[3]]<- NormalizeData(scrna3.list[[3]], normalization.method = "LogNormalize", scale.factor = 10000)



## Find variables


scrna3.list[[1]]<- FindVariableFeatures(scrna3.list[[1]], selection.method = "vst", nfeatures = 2000)

scrna3.list[[2]]<- FindVariableFeatures(scrna3.list[[2]], selection.method = "vst", nfeatures = 2000)

scrna3.list[[3]]<- FindVariableFeatures(scrna3.list[[3]], selection.method = "vst", nfeatures = 2000)



# select features that are repeatedly variable across datasets for integration


features <- SelectIntegrationFeatures(object.list = scrna3.list)

# find anchors

anchors <- FindIntegrationAnchors(object.list = scrna3.list, anchor.features = features)


# Integrate data
# this command creates an 'integrated' data assay

fea3cle7.int <- IntegrateData(anchorset = anchors)

DefaultAssay(fea3cle7.int)<-"integrated"


# Run the standard workflow for visualization and clustering
fea3cle7.int <- ScaleData(fea3cle7.int, verbose = FALSE)
fea3cle7.int <- RunPCA(fea3cle7.int, npcs = 30, verbose = FALSE)


```



```{r}
## Determine the ‘dimensionality’ of the dataset

ElbowPlot(fea3cle7.int, ndims = 40)

## Elbow plot: quantitative approach
## https://hbctraining.github.io/scRNA-seq/lessons/elbow_plot_metric.html

# Determine percent of variation associated with each PC
pct <- fea3cle7.int[["pca"]]@stdev / sum(fea3cle7.int[["pca"]]@stdev) * 100

# Calculate cumulative percents for each PC
cumu <- cumsum(pct)

# Determine which PC exhibits cumulative percent greater than 90% and % variation associated with the PC as less than 5
co1 <- which(cumu > 90 & pct < 5)[1]

co1

# Determine the difference between variation of PC and subsequent PC
co2 <- sort(which((pct[1:length(pct) - 1] - pct[2:length(pct)]) > 0.1), decreasing = T)[1] + 1

# last point where change of % of variation is more than 0.1%.
co2


# Minimum of the two calculation
pcs <- min(co1, co2)

pcs


```



```{r}
fea3cle7.int <- RunUMAP(fea3cle7.int, reduction = "pca", dims = 1:18) ## Use default 30, or change the PC number based on above Elbow plot: quantitative approach

fea3cle7.int <- FindNeighbors(fea3cle7.int, reduction = "pca", dims = 1:18)

fea3cle7.int <- FindClusters(fea3cle7.int, resolution = 0.8)

# Visualization

DimPlot(fea3cle7.int, reduction = "umap", label = TRUE, pt.size = 1)
DimPlot(fea3cle7.int, reduction = "umap", group.by = "orig.ident")

## two plots next to each other 

p1 <- DimPlot(fea3cle7.int, reduction = "umap", group.by = "orig.ident")
p2 <- DimPlot(fea3cle7.int, reduction = "umap", label = TRUE, repel = TRUE)
p1 + p2

### split the UMAPs by samples 

DimPlot(fea3cle7.int, reduction = "umap", split.by = "orig.ident", pt.size = 1)


### group the UMAPs by samples. 

DimPlot(fea3cle7.int, reduction = "umap", group.by = "orig.ident", pt.size = 1)

```
